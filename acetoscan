#!/bin/bash

# File: AcetoScan
# Last modified: tor maj 23, 2019  12:08
# Sign: JN

set -euo pipefail

clear
echo " 
   ██                   █            ▓███▒                     
   ██                   █           █▓  ░█                     
  ▒██▒   ▓██▒   ███   █████   ███   █       ▓██▒  ░███░  █▒██▒ 
  ▓▒▒▓  ▓█  ▓  ▓▓ ▒█    █    █▓ ▓█  █▓░    ▓█  ▓  █▒ ▒█  █▓ ▒█ 
  █░░█  █░     █   █    █    █   █   ▓██▓  █░         █  █   █ 
  █  █  █      █████    █    █   █      ▓█ █      ▒████  █   █ 
 ▒████▒ █░     █        █    █   █       █ █░     █▒  █  █   █ 
 ▓▒  ▒▓ ▓█  ▓  ▓▓  █    █░   █▓ ▓█  █░  ▓█ ▓█  ▓  █░ ▓█  █   █ 
 █░  ░█  ▓██▒   ███▒    ▒██   ███   ▒████░  ▓██▒  ▒██▒█  █   █"

echo "
###    Dependencies
###    ------------
###    1. Cutadapt(1.18+)    2. Vsearch (v2.13.0)
###    3. NCBI BLAST+ (2.8.1+)
###    4. R (3.5.2) (libraries - phyloseq, ggplot2, plotly, 
       RColorBrewer, plyr, dplyr)"


###    Introduction
echo ""
echo "¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤"
echo ""
echo "> AcetoScan is written by Abhijeet Singh (abhijeetsingh.aau@gmail.com)"
echo "> Version - AcetoScan_V1.0"
echo "> Program for the analysis of FTHFS amplicon sequencing data from 
 Illumina MiSeq platform(2*300bp)
> The Input data must be in fastq.gz format 
> AcetoScan only processes the forward reads 
-.-.-.-.-.-.-.-.-.-.-.-.-.-.=========================
Forward reads files must be *_R1_001.fastq.gz format
-.-.-.-.-.-.-.-.-.-.-.-.-.-.========================="
echo "¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤"

###    getting current working directory
# TODO: Since the INPUT_DATA and OUTPUT_DATA folders are created by the script,
# there is no reason for making sure the cwd is the "AcetoScan directory". The
# only issue to solve is to make sure the helper scripts in "SCRIPTS" are found:
# Find a good way to add them to the PATH!

export CDIR=$(pwd)
#set -e

###    Checking dependencies
echo "Performing dependencies check"
echo ""

Software_check.sh # <======== External script
#bash "${CDIR}/SCRIPTS/Software_check.sh" # <======== external script

###    User input to set the path
echo ""
echo "----->>>>> ${CDIR}"

echo ""
echo "Is \"AcetoScan\" your WORKING DIRECTORY in above path?"
read -p "[y/n]: " REP_1
echo ""

###    getting absolute path in case working directory is different
if [ "${REP_1}" == "y" ]; then
    echo "yes" > /dev/null
else
    echo "Provide absolute path to directory named \"AcetoScan\"
    "
    read -e -p "Absolute path for the AcetoScan directory (use tab-autocompletion): " PIPELINE
fi

###    Checking if path is correct
if [ "${REP_1}" == "n" ]; then
    if [[ -d "${PIPELINE}/SCRIPTS" ]]; then
        echo "" > /dev/null
    else
        echo "Incorrect path, Aborting !!!" ; exit 1
    fi
else
    echo "" > /dev/null
fi

###    setting working directory according to user input
if [ "${REP_1}" == "y" ]; then
    echo "" > /dev/null
else
    export CDIR="${PIPELINE}"
fi

###    getting path for the raw illumina data
echo "#Please provide the absolute path of the raw illumina reads"
read -e -p "Path to Illumina directory (use tab-autocompletion): " READ_PATH

###    Recording the time whent he script was started
start=$(date +%s) #start time of script

###    Checking if the entered path for pipeline is correct
if [[ -d "${READ_PATH}" ]]; then
    echo "" > /dev/null
else
    echo "Incorrect path, Aborting !!!"
    exit 1
fi

###    Defining clustering threshold
echo ""
echo "#Please provide clustering threshold - (0.95)"
read -e -p "Value - (0.0 to 1.0) : " CLUST_THRESHOLD

###    Checking threshold validity
MAXTHRESHOLD=1.0

if (( ${CLUST_THRESHOLD%%.*} < ${MAXTHRESHOLD%%.*} || ( ${CLUST_THRESHOLD%%.*} == ${MAXTHRESHOLD%%.*} \
    && ${CLUST_THRESHOLD##*.} < ${MAXTHRESHOLD##*.} ) )) > /dev/null ; then    
    echo "" > /dev/null
else
    echo "Invalid threshold: value must be between 0.0 and 1.0" && exit 1
fi

###    Getting processors information
THREADS=$(nproc 2> /dev/null || sysctl -n hw.ncpu 2> /dev/null || getconf _NPROCESSORS_ONLN 2> /dev/null)

###    Removing old directories
# TODO: Check (and warn?) for presence before delete?
rm -rf "${CDIR}/INPUT_DATA"
rm -rf "${CDIR}/OUTPUT_DATA"
rm -rf "${CDIR}/ACETOSCAN_RESULT"

###    find illumina raw reads and making soft links to the data
mkdir -v -p "${CDIR}/INPUT_DATA"
if ! cd "${CDIR}/INPUT_DATA/" ; then
    echo "Error: could not cd to ${CDIR}/INPUT_DATA/"
    exit 1
fi

find "${READ_PATH}" -name '*_R1_001.fastq.gz' -exec ln -s {} "${CDIR}/INPUT_DATA/" \; 2> /dev/null

###    Checking if link exist
if [ ! -n "$(find "${CDIR}/INPUT_DATA/" -maxdepth 1 -type l -name '*_R1_001.fastq.gz' -print -quit)" ] ; then
    echo "Input files \"*_R1_001.fastq.gz\" not found in ${CDIR}/INPUT_DATA/, Aborting !!!"
    exit 1
fi

###    Adapter trimming and quality filtering of the raw reads
# TODO: make sure the trimmed folder is created by mother script,
# and found by worker script
#mkdir -p "${CDIR}/OUTPUT_DATA"
mkdir -p "${CDIR}/OUTPUT_DATA/trimmed/FASTA"
echo ""
echo "Performing adapters trimming and quality filtering"

cutadapt_illumina2.sh # <================= external script
#cutadapt_illumina.sh # <================= external script
#bash "${CDIR}/SCRIPTS/cutadapt_illumina.sh" # <================= external script

if [ -e "${CDIR}/OUTPUT_DATA/cutadapt.out" ]; then
    echo "Cutadapt report: -->> cutadapt.out in ${CDIR}/OUTPUT_DATA/"
else
    echo "Error! Cutadapt report cutadapt.out not found in ${CDIR}/OUTPUT_DATA/"
    exit 1
fi

###    Unzipping and preparing variables file
if ! cd "${CDIR}/OUTPUT_DATA/trimmed" ; then
    echo "Error: could not cd to ${CDIR}/OUTPUT_DATA/trimmed"
    exit 1
fi

# Begin fastq2fasta
find "${CDIR}/OUTPUT_DATA/trimmed" -name '*_trimmed_R1.fastq.gz' \
    -exec sh -c 'f="{}"; b=$(basename "${f}" .fastq.gz); cutadapt -o "${CDIR}/OUTPUT_DATA/trimmed/FASTA/${b}.fasta" "$f"' \;

    ## force extracting 
    ## TODO: Do we really need to uncompress? cutadapt can take compressed input
    #gunzip -f ./*.fastq.gz

    ## variable file
    ## TODO: Use find instead of ls
    #ls *trimmed_R1.fastq | while read FASTA_names
    #do
    #    echo "${FASTA_names%%.*}"
    #done > FASTA_names.txt

    #### FastQ to FastA by EMBOSS
    ## TODO: replace seqret with, e.g., cutadapt:
    ##    cutadapt -o output.fasta input.fastq.gz
    #echo ""
    #echo "Converting FastQ to FastA"
    #mkdir -p "${CDIR}/OUTPUT_DATA/trimmed/FASTA"
    #
    #for FASTQ in $(cat FASTA_names.txt)
    #do
    #    seqret \
    #        -sequence "${FASTQ}.fastq" \
    #        -auto Y \
    #        -warning N \
    #        -outseq "${CDIR}/OUTPUT_DATA/trimmed/FASTA/${FASTQ}.fasta"
    #done
## End of fastq2fasta


## Begin Longest best frame analysis
### Mon 20 maj 2019 17:05:50: Try BioPerl script. 
### TODO: If BioPerl is going to be used, make sure it is installed.
find "${CDIR}/OUTPUT_DATA/trimmed/FASTA" -name '*_trimmed_R1.fasta' \
    -execdir sh -c 'f="{}"; b=$(basename "${f}" .fasta); longorf-acetoscan.pl --filter "$f" > "Best_${b}.fas"' \; # <============= external script

#    ###    Longest best frame analysis
#    # preparing variable file
#    if ! cd "${CDIR}/OUTPUT_DATA/trimmed/FASTA" ; then
#        echo "Error: could not cd to ${CDIR}/OUTPUT_DATA/trimmed/FASTA"
#        exit 1
#    fi
#
#    ls *trimmed_R1.fasta > FRAME_INPUTfile.txt
#
#    # analysis
#    for FRAME_INPUT in $(cat FRAME_INPUTfile.txt)
#    do
#        #bash "${CDIR}/SCRIPTS/LongestBestFrame.sh" "${FRAME_INPUT}" # <============= external script
#    done
## End Longest best frame analysis


#########  Mon 20 maj 2019 17:03:43 ##################################
## Begin Preprocessing for Clustering
###    Preprocessing for Clustering
    # preparing variable file
    # TODO: use find or shell expansion instead of ls and cat
    ls Best_*.fasta | while read bestname
    do
        echo "${bestname%%.*}"
    done > file_bestname.txt

    # replace fasta header to file name
    # TODO: use find or shell expansion instead of ls and cat
    for i in $(cat file_bestname.txt)
    do 
        awk '/^>/ {gsub(/.fa(sta)?$/,"",FILENAME);printf(">%s\n",FILENAME);next;} {print}' "${i}.fasta"
    done > pre_All_best.fasta.tmp

    # editing fasta headers
    # TODO: this filtering are potentially done above by the BioPerl script (except the s/Best_//g).
    #sed 's/-/_/g;s/ /_/g;s/:/_/g;s/Best_//g' pre_All_best.fasta.tmp > pre_All_best.fasta
    sed -e 's/-/_/g' \
        -e 's/ /_/g' \
        -e 's/:/_/g' \
        -e 's/Best_//g' pre_All_best.fasta.tmp > pre_All_best.fasta

    # formating input for vsearch
    # TODO: check what this step is doing. Also: Need specific version of seqret!
    # If wrapping fasta sequences is the aim, there is no need for seqret. One
    # example (change '60' to whatever width you need):
    # perl -npe 'if(!/^>/){s/\S{60}/$&\n/g}'  pre_All_best.fasta > All_best.fasta
    seqret \
        -sequence pre_All_best.fasta \
        -auto Y \
        -warning N \
        -outseq All_best.fasta
## End Preprocessing for Clustering


## Begin clustering with VSEARCH
    ###    Clustering with Vsearch (v2.13.0_linux_x86_64)
    mkdir -p "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH"

    # dereplication 
    echo "Performing dereplication on fasta sequences"
    vsearch \
        --derep_fulllength "${CDIR}/OUTPUT_DATA/trimmed/FASTA/All_best.fasta" \
        --output "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/best_derep.fasta" \
        --minseqlength 150 \
        --sizeout \
        --minuniquesize 2 \
        --relabel Unique \
        --uc "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/derep.uc" \
        --log="${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/derep_log"
    echo ""

    # removing chimeras
    echo "Removing chimeras from dereplicated fasta sequences"
    vsearch \
        --uchime_denovo "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/best_derep.fasta" \
        --sizein \
        --sizeout \
        --chimeras "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/chimera.fasta" \
        --nonchimeras "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/nonchimera.fasta" \
        --log="${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/chimera_log.txt"
    echo ""

    # Clustering OTUs
    echo "Removing chimeras from dereplicated fasta sequences"
    vsearch \
        --cluster_size "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/nonchimera.fasta" \
        --id "${CLUST_THRESHOLD}" \
        --centroid "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/pre_OTU.fasta" \
        --otutabout "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/classic_pre_otu_table.txt" \
        --uc "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/clustering_result" \
        --sizein \
        --sizeout \
        --relabel 'OTU_' \
        --biomout "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/pre_OTUtable.biom.json"
    echo ""
## End clustering with VSEARCH



# Preparing input file for filtering of non target sequences
perl -pe '/^>/ ? print "\n" : chomp' ./VSEARCH/pre_OTU.fasta | \
    sed '/^$/d' > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/pre_OTU.fasta.tmp"

###    Filtering non target sequences with BlastX
echo "Filtering non target OTUs"

###    BlastX from NCBI Blast+ (2.8.1)
# TODO: use diamond?
#    diamond makedb --in db.fas -d db
#    diamond blastx -d db -q query.fas -a diamond.hits -p 4
#    diamond view -a diamond.hits.daa -o diamond.hits.m8
blastx \
    -query "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/pre_OTU.fasta.tmp" \
    -db "${CDIR}/ACETOBASE_DB_DIR/AcetoBaseV1" \
    -task blastx \
    -max_target_seqs 1 \
    -num_threads "${THREADS}" \
    -evalue 1e-9 \
    -out "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/blast_results_for_filtering" \
    -outfmt "7 qseqid"

# processing blast result file
sed '/^#/d' ./VSEARCH/blast_results_for_filtering > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/filtered_OTU_list.txt"

# Extracting target sequences
# TODO: iterator variable OTU unused. What is extracted?
for OTU in $(cat ${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/filtered_OTU_list.txt)
do
    grep -A 1 "OTU" "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/pre_OTU.fasta.tmp" > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/filtered_OTU.fasta.tmp"
done 

# processing filtered OTU multifasta file
sed 's/-//g' "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/filtered_OTU.fasta.tmp" | \
    sed '/^#/d' > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/filtered_OTU.fasta"

###    Generating OTU table with filtered/target OTUs
echo ""
echo "Generating OTU table"
vsearch \
    --usearch_global "${CDIR}/OUTPUT_DATA/trimmed/FASTA/All_best.fasta" \
    -db "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/filtered_OTU.fasta" \
    --id 0.95 \
    --otutabout "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table.tmp"

sed -e 's/_trimmed_R1//g' "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table.tmp" > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table.pre"
echo ""

###    Sorting OTUs in assending order
# TODO: no need for cat
#sed -e 's/#OTU ID/ID/' \
#    -e 's/OTU_//' \
#    -e 's/^/OTU_/' \
#     "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table.pre" | \
#    sort -n > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table.txt"
cat "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table.pre" | \
    sed -e 's/#OTU ID/ID/' | \
    sed -e 's/OTU_//' | \
    sort -n | \
        sed -e 's/^/OTU_/' > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table.txt"

###    Assigning taxonomy 
echo ""
echo "Searching for taxonomy"

cut -d ";" -f1 "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/filtered_OTU.fasta" > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU.fasta"

blastx \
    -query "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU.fasta" \
    -db "${CDIR}/ACETOBASE_DB_DIR/AcetoBaseV1" \
    -task blastx \
    -max_target_seqs 1 \
    -num_threads "${THREADS}" \
    -evalue 1e-9 \
    -out "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/OTUblast.txt.tmp" \
    -outfmt "6 qseqid saccver pident"

###    Preparing OTU taxonomy table
sed -e 's/;tax=/,/g' "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/OTUblast.txt.tmp" | \
    sed '1s/^/#OTU,Subject_Accession,Kingdom,Phylum,Class,Order,Family,Genus,Species,Percentage_identity\n/' > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_TAX_table_pre"

#    making tab to comma
sed -e 's/\t/,/g' "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_TAX_table_pre" > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_TAX_table_full.csv"

###    Translating OTU nucleotide sequence to Amino acid based on best frame analysis
rm -rf "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/Translation"
mkdir -p "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/Translation"
if ! cd "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/Translation" ; then
    echo "Error: could not cd to ${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/Translation"
    exit 1
fi
cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU.fasta" .

Translation_LBF.sh FTHFS_OTU.fasta  # <============== external script
#bash "${CDIR}/SCRIPTS/Translation_LBF.sh" FTHFS_OTU.fasta  # <============== external script

###    fixing taxonomy to OTU fasta header 
cd "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/" || echo "Error: could not cd to !$" && exit 1
if ! cd "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/" ; then
    echo "Error: could not cd to ${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/"
    exit 1
fi

# TODO: no need for cat
#cat OTUblast.txt.tmp | sed 's/;tax=/\t/g' | \
#    awk -F "\t" '{print $1,$3,$4}' | \
#    sed  '1s/^/OTU_ID,Kingdom,Phylum,Class,Order,Family,Genus,Species,Percentage_identity \n/' | \
#    sed 's/ /,/g' > FTHFS_TAX_table.txt
sed 's/;tax=/\t/g' OTUblast.txt.tmp | \
    awk -F "\t" '{print $1,$3,$4}' | \
    sed -e '1s/^/OTU_ID,Kingdom,Phylum,Class,Order,Family,Genus,Species,Percentage_identity \n/' \
        -e 's/ /,/g' > FTHFS_TAX_table.txt

###    Preparing the input for R analysis
sed 's/,/\t/g' "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_TAX_table.txt" | \
    awk 'NF{NF--};1' | \
    sed 's/ /\t/g'> "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_TAX_table_R.txt"

# TODO: cat? Use cp, mv, or ln -s instead?
cat "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table.txt" > "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table_R.txt"

###    R analysis
mkdir -p "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/VISUALIZATION"
if ! cd "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/VISUALIZATION" ; then
    echo "Error: could not cd to ${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/VISUALIZATION"
    exit 1
fi
cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table_R.txt" .
cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_TAX_table_R.txt" .

#cp $CDIR/SCRIPTS/AcetoScan_Visualization.R .

RPATH=$(which R)
echo -e "\n\n\n"
echo "Preparing graphics"
echo -e "\n\n\n"

# TODO: use Rscript instead of R
"${RPATH}" \
    --slave \
    --no-restore \
    --silent \
    --quiet \
    --file="${CDIR}/SCRIPTS/AcetoScan_Visualization.R" > /dev/null

###    Putting everything together in a Result DIRECTORY
mkdir -p "${CDIR}/ACETOSCAN_RESULT"
cd "${CDIR}/ACETOSCAN_RESULT" || echo "Error: could not cd to !$" && exit 1
if ! cd "${CDIR}/ACETOSCAN_RESULT" ; then
    echo "Error: could not cd to ${CDIR}/ACETOSCAN_RESULT"
    exit 1
fi
cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU.fasta" .
cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_OTU_table.txt" .
cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_TAX_table_full.csv" .
cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/FTHFS_TAX_table.txt" .
cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/Translation/Translation*.fasta" .

if [ -f "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/VISUALIZATION/Barplot_Phylum_Absolute_abundance.pdf" ]; then
    cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/VISUALIZATION/*Barplot*.pdf" .
    cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/VISUALIZATION/*Heatmap*.pdf" .
    cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/VISUALIZATION/Phyloseq_object_processing_info.txt" .
    cp "${CDIR}/OUTPUT_DATA/trimmed/FASTA/VSEARCH/VISUALIZATION/*.html" .
else
    echo "" > /dev/null
fi

###    Getting final information
end=$(date +%s) # end time of script
runtime=$(((end - start))) # calculate runtime

DATASIZE=$(du "$READ_PATH/*" -ch | grep "total" | sed 's/total//')

echo ""
echo "-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.=================================================="
echo "Final results are in Directory \"ACETOSCAN_RESULT\" in path ${CDIR}/ACETOSCAN_RESULT"
echo "-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.=================================================="
echo ""
echo "${DATASIZE} of data processed in ${runtime} seconds"

#     Print blank lines
echo -e "\n\n\n"

###    End of script

