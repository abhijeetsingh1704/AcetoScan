#!/bin/bash

# File: AcetoScan
# Last modified: Ons Feb 06, 2020 20:33
# Sign: Abhi

### Setting colour variables
RESTORE='\033[0m'
YELLOW='\033[01;33m'
LRED='\033[01;31m' 

###	set pipefail

set -euo pipefail

###	getting currect working directory to variable

CDIR=$(pwd)

###	acetoscan script

echo -e "${LRED}\
 ___________________________________________________________
|     _    ____ _____ _____ ___  ____   ____    _    _   _  |
|    / \  / ___| ____|_   _/ _ \/ ___| / ___|  / \  | \ | | |
|   / _ \| |   |  _|   | || | | \___ \| |     / _ \ |  \| | |
|  / ___ \ |___| |___  | || |_| |___) | |___ / ___ \| |\  | |
| /_/   \_\____|_____| |_| \___/|____/ \____/_/   \_\_| \_| |
|___________________________________________________________|
${RESTORE}\n#\t${YELLOW}Â©Abhijeet Singh${RESTORE}
#\t${YELLOW}-abhijeetsingh.aau@gmail.com${RESTORE}
"

###    Recording the time whent he script was started

start=$(date +%s) #start time of script

###	Variable for the backup

DATE=$(date | sed 's/ /_/g;s/:/-/g;s/__/_/g' )

###     Setting up variables

input_dir=""            
output_dir=""           
read_type=""
max_len=""
min_len=""
qual=""            
cluster_threshold=""
cluster_size=""

###     Username

user=`echo ${SUDO_USER:-${USER}}`

###     Defaults

output_dir_def="/home/$user/acetoscan/output_data"
read_type_def="1"
max_len_def="300"
min_len_def="120"
qual_def="20" 
cluster_threshold_def="0.80"
cluster_size_def="2"
version_def="0.1.0"

###    Getting processors information

THREADS=$(nproc 2> /dev/null || sysctl -n hw.ncpu 2> /dev/null || getconf _NPROCESSORS_ONLN 2> /dev/null)

###     Defining flags

#       function

usage() {
echo "Usage   : $0 [-i <input directory>] [-o <output directory>] [-m <max_length>] [-n <min_length>] [-q <quality threshold>] [-r <reads type>] [-t <clustering threshold>] [-c <min_cluster size>]
Example : acetoscan -i /<input path>/ -o /<output path>/ -m 300 -n 120 -q 20 -r 1 -t 0.80 -c 2" 1>&2; exit 1;
}


#       flags

while getopts "i:o:m:n:q:r:t:c:hv" flags; 
        do      
                case "${flags}" in
                        
                        i)
                                input_dir=${OPTARG}
                                ;;

                        o)
                                output_dir=${OPTARG}
                                ;;

                        m)
                                max_len=${OPTARG}
                                ;;

                        n)
                                min_len=${OPTARG}
                                ;;

                        q)
                                qual=${OPTARG}
                                ;;
                        
                        r)
                                read_type=${OPTARG}
                                ;;

                        t)
                                cluster_threshold=${OPTARG}
                                ;;
                                
                        c)
                                cluster_size=${OPTARG}
                                ;;

                        h)
                                echo "
Example : acetoscan -i /<input path>/ -o /<output path>/ -m 300 -n 120 -q 20 -r 1 -t 0.80 -c 2

        -i      Input directory containing raw illumina data
        -o      Output directory
                        :default = /home/${user}/acetoscan/output_data
        -m      Maximum length of sequence after quality filtering
                        :defalut max_length = 300
        -n      Minimum length of sequence after quality filtering
                        :defalut min_length = 120
        -q      Quality threshold for the sequences 
                        :default quality threshold = 20
        -r      Read type either forward or reverse reads 
                        1 = forward reads (default)
                        2 = reverse reads
        -t      Clustering threshold
                        :default cluster threshold = 0.80 (80 %)
        -c      Minimum cluster size
                        :default minimum cluster size = 2
        -h      print Help
        -v      print acetoscan version"
                                exit                                
                                ;;

                        v)
                                echo -e "#\tAcetoScan version: ${YELLOW}${version_def}${RESTORE}"
                                echo -e "#\tVisit \"${YELLOW}https://acetobase.molbio.slu.se/${RESTORE}\" for more information."
                                exit
                                ;;

                        *)
                                usage
                                exit
                                ;;

                        :)      
                                usage
                                exit
                                ;;
                        
                        \?)
                                usage
                                exit
                                ;;

                esac
        done

shift $((OPTIND-1))

###     check

if ((OPTIND == 1));then
echo -e "\n#\t${LRED}Input directory not provided, Aborting!!!\n###\n${RESTORE}"
        echo ""
        usage
        exit
fi

###	Generating logfile

exec > >(tee -a acetoscan_log )
exec 2> >(tee -a acetoscan_log >&2)

###     Checking input_dir 

if [ ! -d "$input_dir" ] && [ -x "$input_dir" ]; then
        echo -e "\n#\t${LRED}Input directory not provided, Aborting!!!\n###\n${RESTORE}"
        echo ""
        usage
        exit
else
        echo -e "\n#\tContents of input directory: ${YELLOW}$input_dir${RESTORE}"        
        echo -e "\n#============================================================\n"
        INfile=$(find "$input_dir" -iname "*_R1_001.fastq.*" | awk -F . '{print $NF}' | head -1 )
        forward_read_filecount=$(find "$input_dir" -name "*_R1_001.fastq.${INfile}" | wc -l)
        reverse_read_filecount=$(find "$input_dir" -name "*_R2_001.fastq.${INfile}" | wc -l)
        #
        forward_read_filesize=$(find "$input_dir" -name "*_R1_001.fastq.${INfile}" -print0 | du --files0-from=- -ch | grep "total" | cut -f1)
        reverse_read_filesize=$(find "$input_dir" -name "*_R2_001.fastq.${INfile}" -print0 | du --files0-from=- -ch | grep "total" | cut -f1)
        #
        echo -e "-> Number of forward read files: $forward_read_filecount"
        echo -e "-> Size of forward read files:   $forward_read_filesize"
        echo -e "-> Number of reverse read files: $reverse_read_filecount"
        echo -e "-> Size of reverse read files:   $reverse_read_filesize"
        echo -e "\n#============================================================\n"
        
        
fi



###     Checking output_dir 


if [ "$output_dir" == "" ]; then
        output_dir="$output_dir_def"
        echo -e "\n#\tUsing default output directory: ${YELLOW}$output_dir_def${RESTORE}"
        if [ -d "$output_dir_def" ] ; then
                echo -ne ""
        else
                mkdir -p "$output_dir_def"
        fi
else
        if [  -d "$output_dir" ] && [ -x "$output_dir" ]; then
                echo -e "\n#\tOutput directory: ${YELLOW}$output_dir${RESTORE}"
        else
                if [ ! -d "$output_dir" ]; then   
                        mkdir -p "$output_dir"
                        echo -e "\n#\tOutput directory: ${YELLOW}$output_dir${RESTORE}"
                else
                       echo -e "\n#\t${LRED}Cannot access/create $output_dir${RESTORE}" 
                fi
        fi
fi

###     setting up working directory

export WKDIR="$output_dir"

###     Checking maximum length threshold

if [ "$max_len" == "" ];then
        max_len="$max_len_def"
        echo -e "\n#\tUsing default max_length: ${YELLOW}${max_len_def}${RESTORE}"
else
       echo -e "\n#\tUsing max_length: ${YELLOW}${max_len}${RESTORE}"
fi

###     Checking minimum length threshold

if [ "$min_len" == "" ];then
        min_len="$min_len_def"
        echo -e "\n#\tUsing default min_length: ${YELLOW}${min_len_def}${RESTORE}"
else
       echo -e "\n#\tUsing min_length: ${YELLOW}${min_len}${RESTORE}"
fi

###     Checking quality threshold

if [ "$qual" == "" ];then
        qual="$qual_def"
        echo -e "\n#\tUsing default quality threshold: ${YELLOW}${qual_def}${RESTORE}"
else
       echo -e "\n#\tUsing quality threshold: ${YELLOW}${qual}${RESTORE}"
fi

###     Checking read type

if [ "$read_type" == "" ];then
        read_type="$read_type_def"
        echo -e "\n#\tUsing default: ${YELLOW}R1 / Forward reads${RESTORE}"
else
       echo -e "\n#\tUsing ${YELLOW}R${read_type} reads${RESTORE}"
fi

#       read variable

export reads="R${read_type}"
export MaxL="$max_len"
export MinL="$min_len"
export QT="$qual"
export INfileext="${INfile}"

###     Checking clustering threshold

if [ "$cluster_threshold" == "" ];then
        cluster_threshold="$cluster_threshold_def"
        echo -e "\n#\tUsing default clustering threshold: ${YELLOW}${cluster_threshold_def}${RESTORE}"
else
        echo -e "\n#\tClustering threshold: ${YELLOW}$cluster_threshold${RESTORE}"
fi

###     Checking minimum clustering size

if [ "$cluster_size" == "" ];then
        cluster_size="$cluster_size_def"
        echo -e "\n#\tUsing default minimum cluster size: ${YELLOW}${cluster_size_def}${RESTORE}"
else
        echo -e "\n#\tMinimum cluster size: ${YELLOW}$cluster_size${RESTORE}"
fi

###    Checking threshold validity

MAXTHRESHOLD=1.0

if (( ${cluster_threshold%%.*} < ${MAXTHRESHOLD%%.*} || ( ${cluster_threshold%%.*} == ${MAXTHRESHOLD%%.*} \
    && ${cluster_threshold##*.} < ${MAXTHRESHOLD##*.} ) )) > /dev/null ; then    
    echo "" > /dev/null
else
    echo -e "\n#\tInvalid threshold: value must be between 0.0 and 1.0" && exit 1
fi

###     Checking of output_data directory is has content

###    Checking and cleaning the input_data and output_data directory

if [ ! -z "$(ls -A "$output_dir")" ]; then
   echo -e "\n#\t${LRED}WARNING: directory \"$output_dir\" is not empty, possibility of data loss!!!${RESTORE}"
   
        #       Compressing previous data
        echo -e "\n#\t${LRED}Compressing previous data to /home/$user/acetoscan_backup_${DATE}.tar.gz${RESTORE}"
        tar -zcf /home/$user/acetoscan_backup_${DATE}.tar.gz ${WKDIR}
       
        #       Cleaning
        echo -e "\n#\t${LRED}Removing previous data from ${WKDIR}${RESTORE}"
        rm -f ${WKDIR}/input_data/*
        rm -rf ${WKDIR}/output_data/*
        rm -f ${WKDIR}/acetoscan_result/*
else
        #       creating new directories
        echo -e "\n#\tCreating directories\n"
        mkdir -v -p "${WKDIR}/input_data"
        mkdir -v -p "${WKDIR}/output_data"
        mkdir -v -p "${WKDIR}/acetoscan_result"
fi

###    Checking dependencies

echo -e "\n#\t${YELLOW}Performing dependencies check${RESTORE}"
export PATH="/home/$user/acetoscan/acetoscan_bin/:${PATH}"
AcetoScan_software_check.sh # <======== External script

###    find illumina raw reads and making soft links to the data

if ! cd "${WKDIR}/input_data/" ; then
    echo -e "\n#\t${LRED}Error: could not access ${WKDIR}/input_data/${RESTORE}"
    exit 1
fi

#       softlinks

find "${input_dir}" -name "*_${reads}_001.fastq.${INfile}" -exec ln -s {} "${WKDIR}/input_data/" \; #2> /dev/null

###    Checking if link exist

if [ ! -n "$(find "${WKDIR}/input_data/" -maxdepth 1 -type l -name "*_${reads}_001.fastq.${INfile}" -print -quit)" ] ; then
    echo -e "\n#\t${LRED}Input files \"*_${reads}*.fastq.${INfile}\" not found in ${WKDIR}/input_data/, Aborting !!!\n###\n${RESTORE}"
    exit 1
fi



###     Function for the Spinner


spin=( '/' '-' '\' '|' )

processing() {
              while [ 1 ]
                do
                   for s in "${spin[@]}"
                        do
                                echo -ne "\r[Processing:]$s"
                                sleep 0.25
                        done
                done &
}

###    Adapter trimming and quality filtering of the raw reads

mkdir -p "${WKDIR}/output_data/trimmed"
echo -e "\n#\t${YELLOW}Performing adapters trimming and quality filtering${RESTORE}"
echo -e "\n#\t${LRED}OBS: This might take a while!${RESTORE}\n"

###     CUTADAPT <--- from external script

#       Starting spinner for cudadapt                
        processing
        pid=$!
	disown
        
        ###	cutadapt external script        
        AcetoScan_cutadapt.sh   # <============= external script
        
#       closing spinner for cudadapt
        echo -ne "Done\n"
        kill $pid 

# 	cleaning input directory links

find "${WKDIR}/input_data/" -maxdepth 1 -type l -name "*_${reads}_001.fastq.${INfile}" -exec rm {} \;   


###     Begin Longest best frame analysis <--- from external script

echo -e "\n#\t${YELLOW}Performing longest best frame analysis${RESTORE}"
echo -e "\n#\t${LRED}OBS: This might take a while!\n${RESTORE}"

#       Starting spinner for best frame script
        processing
        pid=$!
	disown
        
        #longorf-acetoscan external script
        
        find ${WKDIR}/output_data/trimmed/ -name "*_trimmed_${reads}.fasta" \
        -execdir sh -c 'f="{}"; b=$(basename "${f}" .fasta); AcetoScan_longorf.pl --filter "$f" > "Best_${b}.fasta"' \; # <============= external script
        
#       closing spinner for best frame script
        echo -ne "Done\n"        
        kill $pid 

###     Preprocessing for Clustering

cd "${WKDIR}/output_data/trimmed"
echo -e "\n#\t${YELLOW}Preprocessing for clustering${RESTORE}"
echo ""

#       Starting spinner for Preprocessing	
	processing
	pid=$!
	disown

#       Finding and replacing the fasta header with file name

find ${WKDIR}/output_data/ -type f -iname "Best*.fasta" -printf "%f\n" | while read x;
        do 
             awk '/^>/ {gsub(/.fa(sta)?$/,"",FILENAME);printf(">%s\n",FILENAME);next;} {print}' "${x}"
        done > All_best.fasta.tmp

###     Formating input for vsearch

perl -npe 'if(!/^>/){s/\S{60}/$&\n/g};{s/-/_/g}' All_best.fasta.tmp > All_best.fasta

#       closing spinner for Preprocessing
	echo -ne "Done\n"        
	kill $pid
	echo ""

###		Checking if All_best.fasta is not empty

if [ ! -s "${WKDIR}/output_data/trimmed/All_best.fasta" ]; then
	echo -e "\n#\t${LRED}No sequence to proceed, Aborting!!!\n###\n${RESTORE}"
	exit
fi


###     Begin clustering with VSEARCH (v2.13.0_linux_x86_64)

mkdir -v -p "${WKDIR}/output_data/trimmed/VSEARCH"
echo -e "\n#\tBegin clustering at ${LRED}$cluster_threshold %${RESTORE}"

    #   dereplication 

        echo -e "\n#\t${YELLOW}Performing dereplication${RESTORE}\n"
        vsearch \
                --derep_fulllength "${WKDIR}/output_data/trimmed/All_best.fasta" \
                --output "${WKDIR}/output_data/trimmed/VSEARCH/best_derep.fasta" \
                --sizeout \
                --minuniquesize "${cluster_size}" \
                --relabel Unique \
                --uc "${WKDIR}/output_data/trimmed/VSEARCH/derep.uc" \
                --log="${WKDIR}/output_data/trimmed/VSEARCH/derep_log"
    
    #   removing chimeras

        echo -e "\n#\t${YELLOW}Removing chimera${RESTORE}\n"
        vsearch \
                --uchime_denovo "${WKDIR}/output_data/trimmed/VSEARCH/best_derep.fasta" \
                --sizein \
                --sizeout \
                --chimeras "${WKDIR}/output_data/trimmed/VSEARCH/chimera.fasta" \
                --nonchimeras "${WKDIR}/output_data/trimmed/VSEARCH/nonchimera.fasta" \
                --log="${WKDIR}/output_data/trimmed/VSEARCH/chimera_log.txt"
    
    # Clustering OTUs

        echo -e "\n#\t${YELLOW}Clustering OTUs at ${cluster_threshold} % sequence similarity${RESTORE}\n"
        vsearch \
                --cluster_size "${WKDIR}/output_data/trimmed/VSEARCH/nonchimera.fasta" \
                --id "${cluster_threshold}" \
                --centroid "${WKDIR}/output_data/trimmed/VSEARCH/pre_OTU.fasta" \
                --otutabout "${WKDIR}/output_data/trimmed/VSEARCH/classic_pre_otu_table.txt" \
                --uc "${WKDIR}/output_data/trimmed/VSEARCH/clustering_result" \
                --sizein \
                --sizeout \
                --relabel 'OTU_' \
                --biomout "${WKDIR}/output_data/trimmed/VSEARCH/pre_OTUtable.biom.json"
    
###     End of clustering with VSEARCH


###     Preparing input file for filtering of non target sequences

perl -pe '/^>/ ? print "\n" : chomp' ./VSEARCH/pre_OTU.fasta | \
    sed '/^$/d' > "${WKDIR}/output_data/trimmed/VSEARCH/pre_OTU.fasta.tmp"

###    Filtering non target sequences with BlastX from NCBI Blast+ (2.8.1)

echo -e "\n#\t${YELLOW}Filtering non target OTUs${RESTORE}"
echo -e "\n#\t${LRED}OBS: This might take a while!\n${RESTORE}"

#       Starting spinner for blastx filtering
	processing
	pid=$!
	disown
        
        blastx \
                -query "${WKDIR}/output_data/trimmed/VSEARCH/pre_OTU.fasta.tmp" \
                -db "/home/$user/acetoscan/acetobase/AcetoBase" \
                -task blastx \
                -max_target_seqs 1 \
                -num_threads "${THREADS}" \
                -evalue 1e-5 \
                -out "${WKDIR}/output_data/trimmed/VSEARCH/blast_results_for_filtering" \
                -outfmt "7 qseqid" 2> /dev/null

###     Processing blast result file, deleting commented lines
sed '/^#/d' ./VSEARCH/blast_results_for_filtering | uniq > "${WKDIR}/output_data/trimmed/VSEARCH/filtered_OTU_list.txt"

###     Extracting target sequences

while read line;
      do
         grep -w -A 1 "$line" "${WKDIR}/output_data/trimmed/VSEARCH/pre_OTU.fasta.tmp" >> "${WKDIR}/output_data/trimmed/VSEARCH/filtered_OTU.fasta.tmp"
      done < ${WKDIR}/output_data/trimmed/VSEARCH/filtered_OTU_list.txt
		
#       Closing spinner for blastx filtering
	echo -ne "Done\n"
	kill $pid
	
###		Checking if filtered_OTU.fasta.tmp is not empty

if [ ! -s "${WKDIR}/output_data/trimmed/VSEARCH/filtered_OTU.fasta.tmp" ]; then
	echo -e "\n#\t${LRED}No sequence to proceed, Aborting!!!\n###\n${RESTORE}"
	exit
fi

        # processing filtered OTU multifasta file

        sed -e 's/-/_/g;/^#/d' "${WKDIR}/output_data/trimmed/VSEARCH/filtered_OTU.fasta.tmp" > "${WKDIR}/output_data/trimmed/VSEARCH/filtered_OTU.fasta"



###    Generating OTU table with filtered/target OTUs

        echo -e "\n#\t${YELLOW}Generating OTU table${RESTORE}\n"
        vsearch \
                --usearch_global "${WKDIR}/output_data/trimmed/All_best.fasta" \
                --db "${WKDIR}/output_data/trimmed/VSEARCH/filtered_OTU.fasta.tmp" \
                --id ${cluster_threshold} \
                --otutabout "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU_table.tmp"

###     Processing Sample name

sed -e "s/Best_//g;s/_trimmed_${reads}//g" "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU_table.tmp" > "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU_table.pre"

###    Sorting OTUs in assending order

sed -e 's/#OTU ID/ID/' "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU_table.pre" \
-e 's/OTU_//' | sort -n | sed -e 's/^/OTU_/' > "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU_table.txt"

###     Preparing OTU table for R

cp "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU_table.txt" "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU_table_R.txt"

###    Assigning taxonomy 

echo -e "\n#\t${YELLOW}Assigning taxonomy${RESTORE}"
echo -e "\n#\t${LRED}OBS: This might take a while!${RESTORE}\n"

#       Starting spinner for taxonomic assignment
	processing
	pid=$!
	disown

        cut -d ";" -f1 "${WKDIR}/output_data/trimmed/VSEARCH/filtered_OTU.fasta" > "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU.fasta"

        # assigning taxonomy by translated nucleotide query wait protein database
        blastx \
                -query "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU.fasta" \
                -db "/home/$user/acetoscan/acetobase/AcetoBase" \
                -task blastx \
                -max_target_seqs 1 \
                -num_threads "${THREADS}" \
                -evalue 1e-5 \
                -out "${WKDIR}/output_data/trimmed/VSEARCH/OTU_blast.txt.tmp" \
                -outfmt "6 qseqid saccver pident" 2> /dev/null

#       closing spinner for taxonomic assignment
	echo -ne "Done\n"
	kill $pid
	
###     Removing duplicates
awk '!a[$1]++' "${WKDIR}/output_data/trimmed/VSEARCH/OTU_blast.txt.tmp" >  "${WKDIR}/output_data/trimmed/VSEARCH/OTUblast.txt.tmp"
rm "${WKDIR}/output_data/trimmed/VSEARCH/OTU_blast.txt.tmp"	

###    Preparing OTU taxonomy table

sed -e 's/;tax=/,/g' "${WKDIR}/output_data/trimmed/VSEARCH/OTUblast.txt.tmp" | \
sed '1s/^/#OTU,Subject_Accession,Kingdom,Phylum,Class,Order,Family,Genus,Species,Percentage_identity\n/' > "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_TAX_table_pre"

#    making tab to comma
sed -e 's/\t/,/g' "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_TAX_table_pre" > "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_TAX_table_full.csv"

###    fixing taxonomy to OTU fasta header 

cd "${WKDIR}/output_data/trimmed/VSEARCH/" 
if ! cd "${WKDIR}/output_data/trimmed/VSEARCH/" ; then
    echo -e "\n#Error: could not access ${WKDIR}/output_data/trimmed/VSEARCH/"
    exit 1
fi

###     Making Tax table
sed 's/;tax=/\t/g' OTUblast.txt.tmp | \
    awk -F "\t" '{print $1,$3,$4}' | \
    sed -e '1s/^/OTU_ID,Kingdom,Phylum,Class,Order,Family,Genus,Species,Percentage_identity \n/' \
        -e 's/ /,/g' > FTHFS_TAX_table.txt

#########################################################################
#       Multiple sequence alignment by mafft

echo -e "\n#\t${YELLOW}Performing Multiple Sequence Alignment${RESTORE}\n"
mafft --reorder --thread "${THREADS}" FTHFS_OTU.fasta > FTHFS_OTU.aln

#       Phylogenetic tree construction by FastTree
echo -e "\n#\t${YELLOW}Preparing phylogenetic tree${RESTORE}\n"
fasttree -nt -gtr FTHFS_OTU.aln > FTHFS_OTU.tree

#########################################################################

###    Preparing the input for R analysis

sed 's/,/\t/g' "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_TAX_table.txt" | \
    awk 'NF{NF--};1' | \
    sed 's/ /\t/g'> "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_TAX_table_R.txt"
    
 ###	Preparing metadata file, input for R analysis
 
 head -1 "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU_table.txt" | \
 	sed 's/\t/\n/g' | \
	sed '/OTU_ID/d' | \
	sort | awk '{print $0 "\t" FNR}' | \
	awk '{$2=sprintf("U%05.0f", $2)}1' | \
	sed '1i\UNIQUENAMES' | \
	sed 's/UNIQUENAMES/\tUNIQUENAMES/' > "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_SAMPLE_table_R.txt"

###    Preparing input for R analysis

echo ""
mkdir -v -p "${WKDIR}/output_data/trimmed/VSEARCH/Visualization"
if ! cd "${WKDIR}/output_data/trimmed/VSEARCH/Visualization" ; then
    echo -e "\n#Error: could not access ${WKDIR}/output_data/trimmed/VSEARCH/Visualization"
    exit 1
fi

cp "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU_table_R.txt" .
cp "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_TAX_table_R.txt" .
cp "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_SAMPLE_table_R.txt" .
cp "${WKDIR}/output_data/trimmed/VSEARCH/FTHFS_OTU.tree" .
cp "/home/$user/acetoscan/acetoscan_bin/AcetoScan_Visualization.R" .

###     Running R script

RPATH=$(which R)
echo -e "\n#\t${YELLOW}Preparing graphics${RESTORE}"

echo -e "\n#\tIn case of ${LRED}execution halt${RESTORE}, access data in path \n\t${YELLOW}${WKDIR}/output_data/trimmed/VSEARCH/${RESTORE}\n"

###     Rscript not working

"${RPATH}" \
    --slave \
    --no-restore \
    --silent \
    --quiet \
    --file="AcetoScan_Visualization.R"

###    Putting everything together in a Result DIRECTORY = acetoscan_result or Visualization

mkdir -v -p "${WKDIR}/acetoscan_result"

        #       result files

cd "${WKDIR}/output_data/trimmed/VSEARCH/" 

cp 	FTHFS_OTU.fasta \
	FTHFS_OTU.tree \
	FTHFS_OTU.aln \
	FTHFS_OTU_table.txt \
	FTHFS_TAX_table.txt \
	FTHFS_SAMPLE_table_R.txt \
	FTHFS_TAX_table_full.csv \
	"${WKDIR}/acetoscan_result"

cd "${WKDIR}/acetoscan_result" 

        #       graphics

if [ -f "${WKDIR}/output_data/trimmed/VSEARCH/Visualization/Alpha_diversity.html" ]; then
        cp ${WKDIR}/output_data/trimmed/VSEARCH/Visualization/* .
        rm AcetoScan_Visualization.R
        rm FTHFS_*table_R.txt
        echo -e "\n\n\n#\tFinal results are in directory \"acetoscan_result\" in path \n\t${YELLOW}${WKDIR}/acetoscan_result${RESTORE}"
        
else
        rm AcetoScan_Visualization.R
        rm FTHFS_*table_R.txt
        echo -e "\n\n\n#\tFinal results are in directory \"Visualization\" in path \n\t${YELLOW}${WKDIR}/output_data/trimmed/VSEARCH/Visualization/${RESTORE}"
        echo -e "\n\n\n#\tAnd OTU table and TAX table in \"acetoscan_result\" in path \n\t${YELLOW}${WKDIR}/acetoscan_result${RESTORE}"
        
fi

###	Moving logfile from previous initial working directory to acetoscan_result directory
###	And removing logfile from previous initial working directory

find ${CDIR} -name "acetoscan_log" -exec sed -r 's/\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[mGK]//g' {} > ${WKDIR}/acetoscan_result/0_acetoscan_${DATE}.log \;
find ${WKDIR}/acetoscan_result/ -name "0_acetoscan_${DATE}.log" -exec sed -i -e '/ambiguous characters./,/done./{//!d};/STEP/d;/(thread/d;/Processing:/d;/Constructing a UPGMA tree/,/done./{//!d};/seconds: Top hits for/d;/Joined/d;/NNI round/d;/seconds: SPR round/d;/ML Lengths/d;/NNI round/d;/Optimizing GTR model/d;/Site likelihoods with/d;/ML split tests for/d' {} \;
find ${CDIR} -name "acetoscan_log" -exec rm {} \;

###    Getting final information

end=$(date +%s) # end time of script
runtime=$(((end - start))) # calculate runtime
processing_data_size=$(find "$input_dir" -iname "*_${reads}_001.fastq.gz" -print0 | du --files0-from=- -ch | grep "total" | cut -f1)
echo -e "\n#\tAcetoscan processed: ${YELLOW} $processing_data_size ${RESTORE} in ${YELLOW} ${runtime} ${RESTORE} seconds\n"

### Greeting

echo -e "\n#\t${YELLOW}${user}${RESTORE}, Thanks for using ${YELLOW}\"AcetoScan\"${RESTORE}\n\n###"

###    End of script


